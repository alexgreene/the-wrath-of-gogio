{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Logistic Regression\n",
    "\n",
    "The likelihood we are trying to maximize is:\n",
    "\n",
    "$$ L(\\beta) = \\prod_{i=1}^n p(x_i^T \\beta)^{y_i} (1 - p(x_i^T \\beta))^{1 - y_i}, $$\n",
    "\n",
    "where $p(z) = \\frac{1}{1 + e^{-z}}$ is the logistic function. In other words, $\\log( \\frac{p(z)}{1 - p(z)} ) = z$. Taking logs, we obtain:\n",
    "\n",
    "\\begin{align*}\n",
    "\\log L(\\beta) = \\sum_{i=1}^n y_i \\log p(x_i^T \\beta) + (1 - y_i) \\log(1 - p(x_i^T \\beta)) &= \\sum_{i=1}^n y_i \\log \\frac{p(x_i^T \\beta)}{1 - p(x_i^T \\beta)} + \\log(1 - p(x_i^T \\beta)) \\\\\n",
    "&= \\sum_{i=1}^n y_i x_i^T \\beta + \\log(1 - p(x_i^T \\beta)) \\\\\n",
    "&= \\sum_{i=1}^n y_i x_i^T \\beta + \\log(1 + e^{x_i^T \\beta})\n",
    "\\end{align*}\n",
    "\n",
    "Now we take the derivative with respect to $\\beta$ to get the gradient.\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial}{\\partial\\beta} \\log L(\\beta) &= \\sum_{i=1}^n x_i y_i - x_i \\frac{e^{x_i^T \\beta}}{1 + e^{x_i^T \\beta}} \\\\\n",
    "&= \\sum_{i=1}^n x_i (y_i - p(x_i^T \\beta)) \\\\\n",
    "&= X^T (y - p(X\\beta)).\n",
    "\\end{align*}\n",
    "\n",
    "And we take the derivative with respect to $\\beta$ again to get the Hessian matrix.\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial^2}{\\partial\\beta^2} \\log L(\\beta) &= -X^T \\underbrace{\\textrm{diag}\\left\\{p(x_i^T \\beta) (1 - p(x_i^T \\beta))\\right\\}}_{W} X\n",
    "\\end{align*}\n",
    "\n",
    "Now we consider Newton's method, an iterative method for finding the maximum of this function:\n",
    "\n",
    "\\begin{align*} \n",
    "\\beta^{(t+1)} &\\leftarrow \\beta^{(t)} - \\left[ \\frac{\\partial^2}{\\partial\\beta^2} \\log L(\\beta^{(t)}) \\right]^{-1} \\frac{\\partial}{\\partial\\beta} \\log L(\\beta^{(t)}) \\\\\n",
    "&= \\beta^{(t)} + (X^T W X)^{-1} X^T (y - p(X\\beta^{(t)}))\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def logistic(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def logistic_regression(X, y):\n",
    "    beta = np.zeros(X.shape[1])\n",
    "    for _ in range(5):\n",
    "        p = logistic(np.dot(X, beta))\n",
    "        w = p * (1 - p)\n",
    "        beta += np.linalg.solve(np.dot(X.T, (w[:, np.newaxis] * X)), np.dot(X.T, y - p))\n",
    "        \n",
    "    p = logistic(np.dot(X, beta))\n",
    "    w = p * (1 - p)\n",
    "    se = np.sqrt(np.diag(np.linalg.inv(np.dot(X.T, (w[:, np.newaxis] * X)))))\n",
    "    \n",
    "    return beta, se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# generate some data\n",
    "X = np.random.randn(1000, 100)\n",
    "y = 1 * (np.random.randn(1000) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.17822066e+00,   5.72936614e-01,  -1.16279084e+00,\n",
       "        -1.79970941e+00,  -7.90654108e-01,   7.14672399e-01,\n",
       "        -4.15126802e-01,   1.54652856e+00,  -1.31705830e+00,\n",
       "         5.47136796e-01,  -9.48387775e-01,   1.84822450e-01,\n",
       "         1.09421346e+00,  -7.53202161e-01,   1.20919011e+00,\n",
       "        -1.31714282e-01,  -1.69463959e+00,   1.87930432e+00,\n",
       "         4.54353207e-02,  -2.29460844e-01,  -9.70618977e-01,\n",
       "         3.71460355e-01,   1.25516126e+00,  -1.17435087e+00,\n",
       "         8.93476654e-02,   7.84153263e-02,  -3.72888080e-01,\n",
       "         1.86502665e+00,  -6.91869561e-01,   4.56499978e-01,\n",
       "        -1.34347286e+00,   6.79682847e-01,   8.43489422e-04,\n",
       "        -1.50485100e+00,   5.64174696e-01,   9.66234639e-01,\n",
       "         7.15517890e-01,   2.54577878e+00,  -4.05769622e-02,\n",
       "         1.86931933e-03,   1.16062667e-01,  -6.79503942e-01,\n",
       "         8.46867171e-01,   7.02812572e-01,  -7.65949194e-01,\n",
       "        -1.00929555e+00,   8.64718794e-01,   9.85437203e-01,\n",
       "        -1.37998708e+00,  -1.77964486e-01,  -2.98067972e-01,\n",
       "         1.16892535e+00,   2.62963268e-02,   8.93404781e-01,\n",
       "         1.07049582e-01,  -1.53387470e+00,  -9.28426170e-01,\n",
       "         9.84977983e-01,   2.45216797e+00,   1.56078099e+00,\n",
       "         1.70509477e+00,   2.00717134e-01,  -2.07971198e-01,\n",
       "         1.21051217e-01,  -4.81460860e-01,   1.67639891e+00,\n",
       "        -1.07643994e+00,  -6.18702849e-01,  -8.50636711e-03,\n",
       "        -3.31754076e-01,   6.47620865e-01,   1.42790028e+00,\n",
       "        -1.12113996e+00,  -1.46308969e+00,   8.42903442e-01,\n",
       "         1.13679337e+00,  -1.54292707e+00,  -6.02225373e-01,\n",
       "         4.59176257e-01,   1.81705471e+00,  -1.42267121e+00,\n",
       "         4.94468989e-01,  -1.14068829e+00,   1.94130922e+00,\n",
       "         2.56853117e-01,  -5.39974810e-01,  -1.70063093e+00,\n",
       "         1.10414538e-01,  -3.37285095e-01,  -2.31464033e+00,\n",
       "         4.14794338e-02,  -3.54611122e-01,   3.66462265e-01,\n",
       "        -1.18892042e-02,  -1.31587541e+00,   8.54136177e-01,\n",
       "        -2.56570371e+00,   1.70497900e+00,   1.20144637e+00,\n",
       "        -1.41232980e-02])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use our logistic regression function\n",
    "beta, se = logistic_regression(X, y)\n",
    "\n",
    "# calculate the z-score for each coefficient\n",
    "z = beta / se\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.635935\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>y</td>        <th>  No. Observations:  </th>  <td>  1000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   900</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>    99</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Wed, 31 May 2017</td> <th>  Pseudo R-squ.:     </th>  <td>0.08252</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>20:00:32</td>     <th>  Log-Likelihood:    </th> <td> -635.93</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -693.13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>  <td>0.1382</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>      <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>   <td>   -0.0812</td> <td>    0.069</td> <td>   -1.178</td> <td> 0.239</td> <td>   -0.216</td> <td>    0.054</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>   <td>    0.0397</td> <td>    0.069</td> <td>    0.573</td> <td> 0.567</td> <td>   -0.096</td> <td>    0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>   <td>   -0.0846</td> <td>    0.073</td> <td>   -1.163</td> <td> 0.245</td> <td>   -0.227</td> <td>    0.058</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>   <td>   -0.1301</td> <td>    0.072</td> <td>   -1.800</td> <td> 0.072</td> <td>   -0.272</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>   <td>   -0.0560</td> <td>    0.071</td> <td>   -0.791</td> <td> 0.429</td> <td>   -0.195</td> <td>    0.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>   <td>    0.0501</td> <td>    0.070</td> <td>    0.715</td> <td> 0.475</td> <td>   -0.087</td> <td>    0.187</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>   <td>   -0.0295</td> <td>    0.071</td> <td>   -0.415</td> <td> 0.678</td> <td>   -0.169</td> <td>    0.110</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>   <td>    0.1101</td> <td>    0.071</td> <td>    1.547</td> <td> 0.122</td> <td>   -0.029</td> <td>    0.250</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>   <td>   -0.0932</td> <td>    0.071</td> <td>   -1.317</td> <td> 0.188</td> <td>   -0.232</td> <td>    0.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>  <td>    0.0382</td> <td>    0.070</td> <td>    0.547</td> <td> 0.584</td> <td>   -0.099</td> <td>    0.175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>  <td>   -0.0698</td> <td>    0.074</td> <td>   -0.948</td> <td> 0.343</td> <td>   -0.214</td> <td>    0.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>  <td>    0.0128</td> <td>    0.070</td> <td>    0.185</td> <td> 0.853</td> <td>   -0.123</td> <td>    0.149</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>  <td>    0.0815</td> <td>    0.074</td> <td>    1.094</td> <td> 0.274</td> <td>   -0.064</td> <td>    0.227</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>  <td>   -0.0547</td> <td>    0.073</td> <td>   -0.753</td> <td> 0.451</td> <td>   -0.197</td> <td>    0.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>  <td>    0.0891</td> <td>    0.074</td> <td>    1.209</td> <td> 0.227</td> <td>   -0.055</td> <td>    0.234</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>  <td>   -0.0089</td> <td>    0.067</td> <td>   -0.132</td> <td> 0.895</td> <td>   -0.141</td> <td>    0.123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>  <td>   -0.1171</td> <td>    0.069</td> <td>   -1.695</td> <td> 0.090</td> <td>   -0.253</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>  <td>    0.1304</td> <td>    0.069</td> <td>    1.879</td> <td> 0.060</td> <td>   -0.006</td> <td>    0.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>  <td>    0.0032</td> <td>    0.071</td> <td>    0.045</td> <td> 0.964</td> <td>   -0.135</td> <td>    0.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>  <td>   -0.0169</td> <td>    0.074</td> <td>   -0.229</td> <td> 0.819</td> <td>   -0.161</td> <td>    0.127</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>  <td>   -0.0691</td> <td>    0.071</td> <td>   -0.971</td> <td> 0.332</td> <td>   -0.209</td> <td>    0.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>  <td>    0.0264</td> <td>    0.071</td> <td>    0.371</td> <td> 0.710</td> <td>   -0.113</td> <td>    0.166</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>  <td>    0.0844</td> <td>    0.067</td> <td>    1.255</td> <td> 0.209</td> <td>   -0.047</td> <td>    0.216</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>  <td>   -0.0833</td> <td>    0.071</td> <td>   -1.174</td> <td> 0.240</td> <td>   -0.222</td> <td>    0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>  <td>    0.0066</td> <td>    0.074</td> <td>    0.089</td> <td> 0.929</td> <td>   -0.139</td> <td>    0.152</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>  <td>    0.0055</td> <td>    0.071</td> <td>    0.078</td> <td> 0.937</td> <td>   -0.133</td> <td>    0.144</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>  <td>   -0.0271</td> <td>    0.073</td> <td>   -0.373</td> <td> 0.709</td> <td>   -0.169</td> <td>    0.115</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>  <td>    0.1373</td> <td>    0.074</td> <td>    1.865</td> <td> 0.062</td> <td>   -0.007</td> <td>    0.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>  <td>   -0.0474</td> <td>    0.069</td> <td>   -0.692</td> <td> 0.489</td> <td>   -0.182</td> <td>    0.087</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th>  <td>    0.0321</td> <td>    0.070</td> <td>    0.456</td> <td> 0.648</td> <td>   -0.106</td> <td>    0.170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th>  <td>   -0.0942</td> <td>    0.070</td> <td>   -1.343</td> <td> 0.179</td> <td>   -0.232</td> <td>    0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32</th>  <td>    0.0470</td> <td>    0.069</td> <td>    0.680</td> <td> 0.497</td> <td>   -0.089</td> <td>    0.183</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33</th>  <td> 5.697e-05</td> <td>    0.068</td> <td>    0.001</td> <td> 0.999</td> <td>   -0.132</td> <td>    0.132</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34</th>  <td>   -0.1026</td> <td>    0.068</td> <td>   -1.505</td> <td> 0.132</td> <td>   -0.236</td> <td>    0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35</th>  <td>    0.0397</td> <td>    0.070</td> <td>    0.564</td> <td> 0.573</td> <td>   -0.098</td> <td>    0.177</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36</th>  <td>    0.0673</td> <td>    0.070</td> <td>    0.966</td> <td> 0.334</td> <td>   -0.069</td> <td>    0.204</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x37</th>  <td>    0.0508</td> <td>    0.071</td> <td>    0.716</td> <td> 0.474</td> <td>   -0.088</td> <td>    0.190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x38</th>  <td>    0.1920</td> <td>    0.075</td> <td>    2.546</td> <td> 0.011</td> <td>    0.044</td> <td>    0.340</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x39</th>  <td>   -0.0028</td> <td>    0.070</td> <td>   -0.041</td> <td> 0.968</td> <td>   -0.140</td> <td>    0.135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x40</th>  <td>    0.0001</td> <td>    0.071</td> <td>    0.002</td> <td> 0.999</td> <td>   -0.138</td> <td>    0.139</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x41</th>  <td>    0.0081</td> <td>    0.070</td> <td>    0.116</td> <td> 0.908</td> <td>   -0.128</td> <td>    0.144</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x42</th>  <td>   -0.0476</td> <td>    0.070</td> <td>   -0.680</td> <td> 0.497</td> <td>   -0.185</td> <td>    0.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x43</th>  <td>    0.0578</td> <td>    0.068</td> <td>    0.847</td> <td> 0.397</td> <td>   -0.076</td> <td>    0.191</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x44</th>  <td>    0.0520</td> <td>    0.074</td> <td>    0.703</td> <td> 0.482</td> <td>   -0.093</td> <td>    0.197</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x45</th>  <td>   -0.0546</td> <td>    0.071</td> <td>   -0.766</td> <td> 0.444</td> <td>   -0.194</td> <td>    0.085</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x46</th>  <td>   -0.0708</td> <td>    0.070</td> <td>   -1.009</td> <td> 0.313</td> <td>   -0.208</td> <td>    0.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x47</th>  <td>    0.0597</td> <td>    0.069</td> <td>    0.865</td> <td> 0.387</td> <td>   -0.076</td> <td>    0.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x48</th>  <td>    0.0710</td> <td>    0.072</td> <td>    0.985</td> <td> 0.324</td> <td>   -0.070</td> <td>    0.212</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x49</th>  <td>   -0.0979</td> <td>    0.071</td> <td>   -1.380</td> <td> 0.168</td> <td>   -0.237</td> <td>    0.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x50</th>  <td>   -0.0126</td> <td>    0.071</td> <td>   -0.178</td> <td> 0.859</td> <td>   -0.151</td> <td>    0.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x51</th>  <td>   -0.0213</td> <td>    0.071</td> <td>   -0.298</td> <td> 0.766</td> <td>   -0.161</td> <td>    0.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x52</th>  <td>    0.0828</td> <td>    0.071</td> <td>    1.169</td> <td> 0.242</td> <td>   -0.056</td> <td>    0.222</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x53</th>  <td>    0.0019</td> <td>    0.072</td> <td>    0.026</td> <td> 0.979</td> <td>   -0.140</td> <td>    0.144</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x54</th>  <td>    0.0641</td> <td>    0.072</td> <td>    0.893</td> <td> 0.372</td> <td>   -0.077</td> <td>    0.205</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x55</th>  <td>    0.0075</td> <td>    0.070</td> <td>    0.107</td> <td> 0.915</td> <td>   -0.130</td> <td>    0.145</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x56</th>  <td>   -0.1086</td> <td>    0.071</td> <td>   -1.534</td> <td> 0.125</td> <td>   -0.247</td> <td>    0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x57</th>  <td>   -0.0686</td> <td>    0.074</td> <td>   -0.928</td> <td> 0.353</td> <td>   -0.213</td> <td>    0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x58</th>  <td>    0.0692</td> <td>    0.070</td> <td>    0.985</td> <td> 0.325</td> <td>   -0.068</td> <td>    0.207</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x59</th>  <td>    0.1752</td> <td>    0.071</td> <td>    2.452</td> <td> 0.014</td> <td>    0.035</td> <td>    0.315</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x60</th>  <td>    0.1094</td> <td>    0.070</td> <td>    1.561</td> <td> 0.119</td> <td>   -0.028</td> <td>    0.247</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x61</th>  <td>    0.1220</td> <td>    0.072</td> <td>    1.705</td> <td> 0.088</td> <td>   -0.018</td> <td>    0.262</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x62</th>  <td>    0.0141</td> <td>    0.070</td> <td>    0.201</td> <td> 0.841</td> <td>   -0.124</td> <td>    0.152</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x63</th>  <td>   -0.0146</td> <td>    0.070</td> <td>   -0.208</td> <td> 0.835</td> <td>   -0.152</td> <td>    0.123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x64</th>  <td>    0.0085</td> <td>    0.070</td> <td>    0.121</td> <td> 0.904</td> <td>   -0.129</td> <td>    0.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x65</th>  <td>   -0.0348</td> <td>    0.072</td> <td>   -0.481</td> <td> 0.630</td> <td>   -0.177</td> <td>    0.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x66</th>  <td>    0.1198</td> <td>    0.071</td> <td>    1.676</td> <td> 0.094</td> <td>   -0.020</td> <td>    0.260</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x67</th>  <td>   -0.0763</td> <td>    0.071</td> <td>   -1.076</td> <td> 0.282</td> <td>   -0.215</td> <td>    0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x68</th>  <td>   -0.0441</td> <td>    0.071</td> <td>   -0.619</td> <td> 0.536</td> <td>   -0.184</td> <td>    0.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x69</th>  <td>   -0.0006</td> <td>    0.066</td> <td>   -0.009</td> <td> 0.993</td> <td>   -0.130</td> <td>    0.129</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x70</th>  <td>   -0.0225</td> <td>    0.068</td> <td>   -0.332</td> <td> 0.740</td> <td>   -0.155</td> <td>    0.110</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x71</th>  <td>    0.0453</td> <td>    0.070</td> <td>    0.648</td> <td> 0.517</td> <td>   -0.092</td> <td>    0.183</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x72</th>  <td>    0.0994</td> <td>    0.070</td> <td>    1.428</td> <td> 0.153</td> <td>   -0.037</td> <td>    0.236</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x73</th>  <td>   -0.0782</td> <td>    0.070</td> <td>   -1.121</td> <td> 0.262</td> <td>   -0.215</td> <td>    0.058</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x74</th>  <td>   -0.1034</td> <td>    0.071</td> <td>   -1.463</td> <td> 0.143</td> <td>   -0.242</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x75</th>  <td>    0.0611</td> <td>    0.073</td> <td>    0.843</td> <td> 0.399</td> <td>   -0.081</td> <td>    0.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x76</th>  <td>    0.0805</td> <td>    0.071</td> <td>    1.137</td> <td> 0.256</td> <td>   -0.058</td> <td>    0.219</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x77</th>  <td>   -0.1109</td> <td>    0.072</td> <td>   -1.543</td> <td> 0.123</td> <td>   -0.252</td> <td>    0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x78</th>  <td>   -0.0439</td> <td>    0.073</td> <td>   -0.602</td> <td> 0.547</td> <td>   -0.187</td> <td>    0.099</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x79</th>  <td>    0.0334</td> <td>    0.073</td> <td>    0.459</td> <td> 0.646</td> <td>   -0.109</td> <td>    0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x80</th>  <td>    0.1293</td> <td>    0.071</td> <td>    1.817</td> <td> 0.069</td> <td>   -0.010</td> <td>    0.269</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x81</th>  <td>   -0.0979</td> <td>    0.069</td> <td>   -1.423</td> <td> 0.155</td> <td>   -0.233</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x82</th>  <td>    0.0344</td> <td>    0.069</td> <td>    0.494</td> <td> 0.621</td> <td>   -0.102</td> <td>    0.171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x83</th>  <td>   -0.0775</td> <td>    0.068</td> <td>   -1.141</td> <td> 0.254</td> <td>   -0.211</td> <td>    0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x84</th>  <td>    0.1341</td> <td>    0.069</td> <td>    1.941</td> <td> 0.052</td> <td>   -0.001</td> <td>    0.270</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x85</th>  <td>    0.0179</td> <td>    0.069</td> <td>    0.257</td> <td> 0.797</td> <td>   -0.118</td> <td>    0.154</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x86</th>  <td>   -0.0394</td> <td>    0.073</td> <td>   -0.540</td> <td> 0.589</td> <td>   -0.182</td> <td>    0.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x87</th>  <td>   -0.1274</td> <td>    0.075</td> <td>   -1.701</td> <td> 0.089</td> <td>   -0.274</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x88</th>  <td>    0.0076</td> <td>    0.069</td> <td>    0.110</td> <td> 0.912</td> <td>   -0.128</td> <td>    0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x89</th>  <td>   -0.0243</td> <td>    0.072</td> <td>   -0.337</td> <td> 0.736</td> <td>   -0.165</td> <td>    0.117</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x90</th>  <td>   -0.1554</td> <td>    0.067</td> <td>   -2.315</td> <td> 0.021</td> <td>   -0.287</td> <td>   -0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x91</th>  <td>    0.0028</td> <td>    0.068</td> <td>    0.041</td> <td> 0.967</td> <td>   -0.131</td> <td>    0.137</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x92</th>  <td>   -0.0241</td> <td>    0.068</td> <td>   -0.355</td> <td> 0.723</td> <td>   -0.157</td> <td>    0.109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x93</th>  <td>    0.0256</td> <td>    0.070</td> <td>    0.366</td> <td> 0.714</td> <td>   -0.111</td> <td>    0.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x94</th>  <td>   -0.0008</td> <td>    0.071</td> <td>   -0.012</td> <td> 0.991</td> <td>   -0.140</td> <td>    0.139</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x95</th>  <td>   -0.0925</td> <td>    0.070</td> <td>   -1.316</td> <td> 0.188</td> <td>   -0.230</td> <td>    0.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x96</th>  <td>    0.0599</td> <td>    0.070</td> <td>    0.854</td> <td> 0.393</td> <td>   -0.077</td> <td>    0.197</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x97</th>  <td>   -0.1817</td> <td>    0.071</td> <td>   -2.566</td> <td> 0.010</td> <td>   -0.320</td> <td>   -0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x98</th>  <td>    0.1180</td> <td>    0.069</td> <td>    1.705</td> <td> 0.088</td> <td>   -0.018</td> <td>    0.254</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x99</th>  <td>    0.0886</td> <td>    0.074</td> <td>    1.201</td> <td> 0.230</td> <td>   -0.056</td> <td>    0.233</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x100</th> <td>   -0.0010</td> <td>    0.069</td> <td>   -0.014</td> <td> 0.989</td> <td>   -0.136</td> <td>    0.134</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                 1000\n",
       "Model:                          Logit   Df Residuals:                      900\n",
       "Method:                           MLE   Df Model:                           99\n",
       "Date:                Wed, 31 May 2017   Pseudo R-squ.:                 0.08252\n",
       "Time:                        20:00:32   Log-Likelihood:                -635.93\n",
       "converged:                       True   LL-Null:                       -693.13\n",
       "                                        LLR p-value:                    0.1382\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1            -0.0812      0.069     -1.178      0.239      -0.216       0.054\n",
       "x2             0.0397      0.069      0.573      0.567      -0.096       0.176\n",
       "x3            -0.0846      0.073     -1.163      0.245      -0.227       0.058\n",
       "x4            -0.1301      0.072     -1.800      0.072      -0.272       0.012\n",
       "x5            -0.0560      0.071     -0.791      0.429      -0.195       0.083\n",
       "x6             0.0501      0.070      0.715      0.475      -0.087       0.187\n",
       "x7            -0.0295      0.071     -0.415      0.678      -0.169       0.110\n",
       "x8             0.1101      0.071      1.547      0.122      -0.029       0.250\n",
       "x9            -0.0932      0.071     -1.317      0.188      -0.232       0.046\n",
       "x10            0.0382      0.070      0.547      0.584      -0.099       0.175\n",
       "x11           -0.0698      0.074     -0.948      0.343      -0.214       0.074\n",
       "x12            0.0128      0.070      0.185      0.853      -0.123       0.149\n",
       "x13            0.0815      0.074      1.094      0.274      -0.064       0.227\n",
       "x14           -0.0547      0.073     -0.753      0.451      -0.197       0.088\n",
       "x15            0.0891      0.074      1.209      0.227      -0.055       0.234\n",
       "x16           -0.0089      0.067     -0.132      0.895      -0.141       0.123\n",
       "x17           -0.1171      0.069     -1.695      0.090      -0.253       0.018\n",
       "x18            0.1304      0.069      1.879      0.060      -0.006       0.266\n",
       "x19            0.0032      0.071      0.045      0.964      -0.135       0.141\n",
       "x20           -0.0169      0.074     -0.229      0.819      -0.161       0.127\n",
       "x21           -0.0691      0.071     -0.971      0.332      -0.209       0.070\n",
       "x22            0.0264      0.071      0.371      0.710      -0.113       0.166\n",
       "x23            0.0844      0.067      1.255      0.209      -0.047       0.216\n",
       "x24           -0.0833      0.071     -1.174      0.240      -0.222       0.056\n",
       "x25            0.0066      0.074      0.089      0.929      -0.139       0.152\n",
       "x26            0.0055      0.071      0.078      0.937      -0.133       0.144\n",
       "x27           -0.0271      0.073     -0.373      0.709      -0.169       0.115\n",
       "x28            0.1373      0.074      1.865      0.062      -0.007       0.282\n",
       "x29           -0.0474      0.069     -0.692      0.489      -0.182       0.087\n",
       "x30            0.0321      0.070      0.456      0.648      -0.106       0.170\n",
       "x31           -0.0942      0.070     -1.343      0.179      -0.232       0.043\n",
       "x32            0.0470      0.069      0.680      0.497      -0.089       0.183\n",
       "x33         5.697e-05      0.068      0.001      0.999      -0.132       0.132\n",
       "x34           -0.1026      0.068     -1.505      0.132      -0.236       0.031\n",
       "x35            0.0397      0.070      0.564      0.573      -0.098       0.177\n",
       "x36            0.0673      0.070      0.966      0.334      -0.069       0.204\n",
       "x37            0.0508      0.071      0.716      0.474      -0.088       0.190\n",
       "x38            0.1920      0.075      2.546      0.011       0.044       0.340\n",
       "x39           -0.0028      0.070     -0.041      0.968      -0.140       0.135\n",
       "x40            0.0001      0.071      0.002      0.999      -0.138       0.139\n",
       "x41            0.0081      0.070      0.116      0.908      -0.128       0.144\n",
       "x42           -0.0476      0.070     -0.680      0.497      -0.185       0.090\n",
       "x43            0.0578      0.068      0.847      0.397      -0.076       0.191\n",
       "x44            0.0520      0.074      0.703      0.482      -0.093       0.197\n",
       "x45           -0.0546      0.071     -0.766      0.444      -0.194       0.085\n",
       "x46           -0.0708      0.070     -1.009      0.313      -0.208       0.067\n",
       "x47            0.0597      0.069      0.865      0.387      -0.076       0.195\n",
       "x48            0.0710      0.072      0.985      0.324      -0.070       0.212\n",
       "x49           -0.0979      0.071     -1.380      0.168      -0.237       0.041\n",
       "x50           -0.0126      0.071     -0.178      0.859      -0.151       0.126\n",
       "x51           -0.0213      0.071     -0.298      0.766      -0.161       0.118\n",
       "x52            0.0828      0.071      1.169      0.242      -0.056       0.222\n",
       "x53            0.0019      0.072      0.026      0.979      -0.140       0.144\n",
       "x54            0.0641      0.072      0.893      0.372      -0.077       0.205\n",
       "x55            0.0075      0.070      0.107      0.915      -0.130       0.145\n",
       "x56           -0.1086      0.071     -1.534      0.125      -0.247       0.030\n",
       "x57           -0.0686      0.074     -0.928      0.353      -0.213       0.076\n",
       "x58            0.0692      0.070      0.985      0.325      -0.068       0.207\n",
       "x59            0.1752      0.071      2.452      0.014       0.035       0.315\n",
       "x60            0.1094      0.070      1.561      0.119      -0.028       0.247\n",
       "x61            0.1220      0.072      1.705      0.088      -0.018       0.262\n",
       "x62            0.0141      0.070      0.201      0.841      -0.124       0.152\n",
       "x63           -0.0146      0.070     -0.208      0.835      -0.152       0.123\n",
       "x64            0.0085      0.070      0.121      0.904      -0.129       0.146\n",
       "x65           -0.0348      0.072     -0.481      0.630      -0.177       0.107\n",
       "x66            0.1198      0.071      1.676      0.094      -0.020       0.260\n",
       "x67           -0.0763      0.071     -1.076      0.282      -0.215       0.063\n",
       "x68           -0.0441      0.071     -0.619      0.536      -0.184       0.096\n",
       "x69           -0.0006      0.066     -0.009      0.993      -0.130       0.129\n",
       "x70           -0.0225      0.068     -0.332      0.740      -0.155       0.110\n",
       "x71            0.0453      0.070      0.648      0.517      -0.092       0.183\n",
       "x72            0.0994      0.070      1.428      0.153      -0.037       0.236\n",
       "x73           -0.0782      0.070     -1.121      0.262      -0.215       0.058\n",
       "x74           -0.1034      0.071     -1.463      0.143      -0.242       0.035\n",
       "x75            0.0611      0.073      0.843      0.399      -0.081       0.203\n",
       "x76            0.0805      0.071      1.137      0.256      -0.058       0.219\n",
       "x77           -0.1109      0.072     -1.543      0.123      -0.252       0.030\n",
       "x78           -0.0439      0.073     -0.602      0.547      -0.187       0.099\n",
       "x79            0.0334      0.073      0.459      0.646      -0.109       0.176\n",
       "x80            0.1293      0.071      1.817      0.069      -0.010       0.269\n",
       "x81           -0.0979      0.069     -1.423      0.155      -0.233       0.037\n",
       "x82            0.0344      0.069      0.494      0.621      -0.102       0.171\n",
       "x83           -0.0775      0.068     -1.141      0.254      -0.211       0.056\n",
       "x84            0.1341      0.069      1.941      0.052      -0.001       0.270\n",
       "x85            0.0179      0.069      0.257      0.797      -0.118       0.154\n",
       "x86           -0.0394      0.073     -0.540      0.589      -0.182       0.104\n",
       "x87           -0.1274      0.075     -1.701      0.089      -0.274       0.019\n",
       "x88            0.0076      0.069      0.110      0.912      -0.128       0.143\n",
       "x89           -0.0243      0.072     -0.337      0.736      -0.165       0.117\n",
       "x90           -0.1554      0.067     -2.315      0.021      -0.287      -0.024\n",
       "x91            0.0028      0.068      0.041      0.967      -0.131       0.137\n",
       "x92           -0.0241      0.068     -0.355      0.723      -0.157       0.109\n",
       "x93            0.0256      0.070      0.366      0.714      -0.111       0.162\n",
       "x94           -0.0008      0.071     -0.012      0.991      -0.140       0.139\n",
       "x95           -0.0925      0.070     -1.316      0.188      -0.230       0.045\n",
       "x96            0.0599      0.070      0.854      0.393      -0.077       0.197\n",
       "x97           -0.1817      0.071     -2.566      0.010      -0.320      -0.043\n",
       "x98            0.1180      0.069      1.705      0.088      -0.018       0.254\n",
       "x99            0.0886      0.074      1.201      0.230      -0.056       0.233\n",
       "x100          -0.0010      0.069     -0.014      0.989      -0.136       0.134\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare the z-scores we got above with statsmodels\n",
    "from statsmodels.api import Logit\n",
    "model = Logit(y, X)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
