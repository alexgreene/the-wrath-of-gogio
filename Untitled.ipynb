{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gamescout_db import db, cur\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", module=\"scipy\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "COLUMNS = ['THREE_RUN_GAME','HT','AT','HT_WPCT','HT_WPCT_1R','HT_WPCT_2R','AT_WPCT','AT_WPCT_1R','AT_WPCT_2R',\n",
    "            'HT_RUN_DIFF','HT_AVG_RS_WIN','HT_AVG_RA_WIN','HT_AVG_RS_LOSS','HT_AVG_RA_LOSS','AT_RUN_DIFF',\n",
    "            'AT_AVG_RS_WIN','AT_AVG_RA_WIN','AT_AVG_RS_LOSS','AT_AVG_RA_LOSS','HP_RUNS_PER_9','HP_BB_PER_9',\n",
    "            'HP_H_PER_9','HP_K_PER_9','HP_IP','HP_ERA','HP_AVG_IP','AP_RUNS_PER_9','AP_BB_PER_9','AP_H_PER_9',\n",
    "            'AP_K_PER_9','AP_IP','AP_ERA','AP_AVG_IP','HT_P_AVG','HT_C_AVG','HT_1B_AVG','HT_2B_AVG','HT_3B_AVG',\n",
    "            'HT_SS_AVG','HT_LF_AVG','HT_CF_AVG','HT_RF_AVG','AT_P_AVG','AT_C_AVG','AT_1B_AVG','AT_2B_AVG',\n",
    "            'AT_3B_AVG','AT_SS_AVG','AT_LF_AVG','AT_CF_AVG','AT_RF_AVG','HT_AVG_HRS','AT_AVG_HRS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_sql('select * from GamePrediction;', con=db).dropna()\n",
    "data['WPCT_DIFF'] = np.abs(data['HT_WPCT'] - data['AT_WPCT'])\n",
    "data['RUN_DIFF'] = np.abs(data['HT_RUN_DIFF'] - data['AT_RUN_DIFF'])\n",
    "data['HT_WIN_DIFF'] = data['HT_AVG_RS_WIN'] - data['HT_AVG_RA_WIN']\n",
    "data['HT_LOSS_DIFF'] = data['HT_AVG_RS_LOSS'] - data['HT_AVG_RA_LOSS']\n",
    "data['AT_WIN_DIFF'] = data['AT_AVG_RS_WIN'] - data['AT_AVG_RA_WIN']\n",
    "data['AT_LOSS_DIFF'] = data['AT_AVG_RS_LOSS'] - data['AT_AVG_RA_LOSS']\n",
    "\n",
    "data['P'] = np.abs(data['HT_P_AVG'] - data['AT_P_AVG'])\n",
    "data['C'] = np.abs(data['HT_C_AVG'] - data['AT_C_AVG'])\n",
    "data['1B'] = np.abs(data['HT_1B_AVG'] - data['AT_1B_AVG'])\n",
    "data['2B'] = np.abs(data['HT_2B_AVG'] - data['AT_2B_AVG'])\n",
    "data['3B'] = np.abs(data['HT_3B_AVG'] - data['AT_3B_AVG'])\n",
    "data['SS'] = np.abs(data['HT_SS_AVG'] - data['AT_SS_AVG'])\n",
    "data['LF'] = np.abs(data['HT_LF_AVG'] - data['AT_LF_AVG'])\n",
    "data['CF'] = np.abs(data['HT_CF_AVG'] - data['AT_CF_AVG'])\n",
    "data['RF'] = np.abs(data['HT_RF_AVG'] - data['AT_RF_AVG'])\n",
    "\n",
    "# data = pd.concat([data, pd.get_dummies(data[\"HT\"]).ix[:, 1:44]], axis = 1)\n",
    "# data = pd.concat([data, pd.get_dummies(data[\"AT\"], prefix=\"_\").ix[:, 1:42]], axis = 1)\n",
    "data = data.dropna() #apply(pd.to_numeric, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WPCT_DIFF</th>\n",
       "      <th>HP_ERA</th>\n",
       "      <th>AP_ERA</th>\n",
       "      <th>HT_WIN_DIFF</th>\n",
       "      <th>HT_LOSS_DIFF</th>\n",
       "      <th>AT_WIN_DIFF</th>\n",
       "      <th>AT_LOSS_DIFF</th>\n",
       "      <th>P</th>\n",
       "      <th>C</th>\n",
       "      <th>1B</th>\n",
       "      <th>2B</th>\n",
       "      <th>3B</th>\n",
       "      <th>SS</th>\n",
       "      <th>LF</th>\n",
       "      <th>CF</th>\n",
       "      <th>RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.250</td>\n",
       "      <td>6.23</td>\n",
       "      <td>2.92</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>-1.50000</td>\n",
       "      <td>1.50000</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.108505</td>\n",
       "      <td>0.109524</td>\n",
       "      <td>0.117117</td>\n",
       "      <td>0.066995</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.096491</td>\n",
       "      <td>0.186379</td>\n",
       "      <td>0.138158</td>\n",
       "      <td>0.122391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.417</td>\n",
       "      <td>4.76</td>\n",
       "      <td>4.91</td>\n",
       "      <td>1.66666</td>\n",
       "      <td>-0.66667</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.069691</td>\n",
       "      <td>0.067322</td>\n",
       "      <td>0.029458</td>\n",
       "      <td>0.066327</td>\n",
       "      <td>0.111285</td>\n",
       "      <td>0.201239</td>\n",
       "      <td>0.044445</td>\n",
       "      <td>0.093593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.200</td>\n",
       "      <td>4.50</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.40000</td>\n",
       "      <td>-1.80000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>0.163194</td>\n",
       "      <td>0.001916</td>\n",
       "      <td>0.050802</td>\n",
       "      <td>0.019078</td>\n",
       "      <td>0.166257</td>\n",
       "      <td>0.211801</td>\n",
       "      <td>0.091812</td>\n",
       "      <td>0.050455</td>\n",
       "      <td>0.047987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.267</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.31</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>2.33333</td>\n",
       "      <td>-0.666670</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.164148</td>\n",
       "      <td>0.032143</td>\n",
       "      <td>0.003760</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.168571</td>\n",
       "      <td>0.060185</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.149167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.50</td>\n",
       "      <td>2.22223</td>\n",
       "      <td>-1.22222</td>\n",
       "      <td>1.50000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.009821</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.025145</td>\n",
       "      <td>0.018140</td>\n",
       "      <td>0.010069</td>\n",
       "      <td>0.112551</td>\n",
       "      <td>0.017391</td>\n",
       "      <td>0.153061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     WPCT_DIFF  HP_ERA  AP_ERA  HT_WIN_DIFF  HT_LOSS_DIFF  AT_WIN_DIFF  \\\n",
       "70       0.250    6.23    2.92      0.50000      -1.50000      1.50000   \n",
       "103      0.417    4.76    4.91      1.66666      -0.66667      0.75000   \n",
       "105      0.200    4.50    1.23      0.40000      -1.80000      1.00000   \n",
       "121      0.267    2.25    2.31      2.00000      -1.00000      2.33333   \n",
       "125      0.000    0.00   13.50      2.22223      -1.22222      1.50000   \n",
       "\n",
       "     AT_LOSS_DIFF         P         C        1B        2B        3B        SS  \\\n",
       "70      -0.250000  0.108505  0.109524  0.117117  0.066995  0.074074  0.096491   \n",
       "103     -1.250000  0.129032  0.069691  0.067322  0.029458  0.066327  0.111285   \n",
       "105     -0.800000  0.163194  0.001916  0.050802  0.019078  0.166257  0.211801   \n",
       "121     -0.666670  0.111111  0.164148  0.032143  0.003760  0.041667  0.168571   \n",
       "125     -0.333333  0.009821  0.008333  0.015385  0.025145  0.018140  0.010069   \n",
       "\n",
       "           LF        CF        RF  \n",
       "70   0.186379  0.138158  0.122391  \n",
       "103  0.201239  0.044445  0.093593  \n",
       "105  0.091812  0.050455  0.047987  \n",
       "121  0.060185  0.142857  0.149167  \n",
       "125  0.112551  0.017391  0.153061  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data[\"THREE_RUN_GAME\"]\n",
    "x = data[['WPCT_DIFF', 'HP_ERA', 'AP_ERA', 'HT_WIN_DIFF', 'HT_LOSS_DIFF', 'AT_WIN_DIFF', 'AT_LOSS_DIFF',\n",
    "         'P', 'C', '1B', '2B', '3B', 'SS', 'LF', 'CF', 'RF']]\n",
    "x.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.07525481, -0.07912611, -0.09514548, -0.20111038,  0.22265354,\n",
       "         0.03761085, -0.20582027, -0.1624905 , -1.10026199, -0.07311682,\n",
       "        -0.38106881,  0.16442528,  0.1685766 ,  0.28686049,  1.20764906,\n",
       "         0.36669355]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = x[:8000]\n",
    "test_x = x[8001:]\n",
    "\n",
    "train_y = y[:8000]\n",
    "test_y = y[8001:]\n",
    "\n",
    "model = linear_model.LogisticRegression(class_weight='balanced')\n",
    "model.fit(train_x, train_y)\n",
    "\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   14.,   213.,  1432.,  1279.,   259.,    50.,    16.,     9.,\n",
       "            6.,     6.]),\n",
       " array([ 0.30558762,  0.37148796,  0.43738831,  0.50328865,  0.56918899,\n",
       "         0.63508933,  0.70098968,  0.76689002,  0.83279036,  0.89869071,\n",
       "         0.96459105]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10362e810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(model.predict_proba(test_x)[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.42      0.58      0.49      1250\n",
      "          1       0.66      0.51      0.58      2034\n",
      "\n",
      "avg / total       0.57      0.54      0.54      3284\n",
      "\n",
      "[[ 722  528]\n",
      " [ 997 1037]]\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(test_x)\n",
    "expected = test_y\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
